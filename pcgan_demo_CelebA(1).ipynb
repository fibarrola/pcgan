{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pcgan_demo_CelebA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jG2KP2prRHjl",
        "uyru1NkeRvgC",
        "F4vAlhZJSVDS"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRbZxRdxQ7YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(\"PCGAN\")\n",
        "\n",
        "# Folder to output result samples\n",
        "parser.add_argument('--result_dir', type=str, default='celeba_result')\n",
        "\n",
        "# Training Parameters\n",
        "parser.add_argument('--batch_size', type=int, default=64)\n",
        "parser.add_argument('--nepoch', type=int, default=15)\n",
        "parser.add_argument('--lr_d', type=float, default=0.0002)\n",
        "parser.add_argument('--lr_g', type=float, default=0.0002)\n",
        "Betas = (0.5, 0.99) # adam optimizer beta1, beta2\n",
        "\n",
        "# Model parameters\n",
        "parser.add_argument('--gan_type', type=str, default='pcgan')\n",
        "parser.add_argument('--nz', type=int, default=100) # number of noise dimension\n",
        "parser.add_argument('--nc', type=int, default=3) # number of result channel\n",
        "parser.add_argument('--nfeature', type=int, default=40)\n",
        "\n",
        "config, _ = parser.parse_known_args()\n",
        "\n",
        "\n",
        "# CHOOSE GAN TYPE\n",
        "# 'scgan' for standard conditional GAN\n",
        "# 'pcgan' for partially conditioned GAN\n",
        "# config.gan_type = 'scgan'\n",
        "config.gan_type = 'pcgan'\n",
        "\n",
        "# FOLDERS CONTAINING THE DATA\n",
        "config.dataset_dir = 'data_faces'\n",
        "config.condition_file = '/content/gdrive/My Drive/list_attr_celeba.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG2KP2prRHjl",
        "colab_type": "text"
      },
      "source": [
        "# Prepping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt21ilo4RCbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e800889-01e8-4266-edfc-e76f16591745"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "cudnn.benchmark = True\n",
        "\n",
        "#set manual seed to a constant get a consistent output\n",
        "manualSeed = random.randint(1, 10000)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "#checking the availability of cuda devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# make output dir\n",
        "if not os.path.exists(config.result_dir):\n",
        "        os.mkdir(config.result_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  5397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R48-NfDhRCeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageFeatureFolder(dset.ImageFolder):\n",
        "    def __init__(self, image_root, landmark_file, transform):\n",
        "        super(ImageFeatureFolder, self).__init__(root=image_root, transform=transform)\n",
        "        with open(landmark_file, 'r') as f:\n",
        "            data = f.read()\n",
        "        data = data.strip().split('\\n')\n",
        "        self.attrs = torch.FloatTensor([list(map(float, line.split()[1:])) for line in data[2:]])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img, _ = super().__getitem__(index)               \n",
        "        return img, self.attrs[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE_a7wxMRChZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GENERATE DATASET and DATALOADER\n",
        "dataset = ImageFeatureFolder(config.dataset_dir, config.condition_file, transform=transforms.Compose([\n",
        "    transforms.CenterCrop(178),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]))\n",
        "dataloader = data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True,num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSWy7EbXRCnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUX FUNCTIONS\n",
        "\n",
        "# Generate soft true/synthetic image labels\n",
        "def make_target(tipo,batch_size):\n",
        "    target = 0.1*torch.rand((batch_size,1),device = device)\n",
        "    wrong_inds = torch.randint(0,batch_size,(batch_size//20,1),device = device)\n",
        "    if tipo == 'synt':\n",
        "        target = target + 0.9\n",
        "        for k in wrong_inds:\n",
        "            target[k] = target[k] - 0.9\n",
        "    elif tipo == 'real':\n",
        "        for k in wrong_inds:\n",
        "            target[k] = target[k] + 0.9\n",
        "    else:\n",
        "        print('ERROR: WRONG TYPE')\n",
        "    return target\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyru1NkeRvgC",
        "colab_type": "text"
      },
      "source": [
        "# Nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTgodP42RCpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.FE = nn.ConvTranspose2d(config.nfeature, 256, 4, 1, 0, bias=False)\n",
        "        self.lay0 = nn.ConvTranspose2d(config.nz, 256, 4, 1, 0, bias=False)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, config.nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, attr):\n",
        "        batch_size = x.size(0)\n",
        "        attr = self.FE(attr.view(batch_size,config.nfeature,1,1))\n",
        "        x = self.lay0(x.view(batch_size,config.nz,1,1))\n",
        "        x = torch.cat([x, attr], 1)\n",
        "        return self.main(x)\n",
        "\n",
        "    def netF(self,y):\n",
        "        y = self.FE(attr.view(batch_size,config.nfeature,1,1))\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhCD_Ja5RCsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standard conditional GAN discriminator network\n",
        "class Discriminator_scgan(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator_scgan, self).__init__()\n",
        "        self.feature_input = nn.Linear(config.nfeature, 64 * 64)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(config.nc + 1, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, attr):\n",
        "        attr = self.feature_input(attr).view(-1, 1, 64, 64)\n",
        "        x = torch.cat([x, attr], 1)\n",
        "        return self.main(x).view(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaDe1DOqRCuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Partially conditioned GAN discriminator network\n",
        "class Discriminator_pcgan(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator_pcgan, self).__init__()\n",
        "        self.feature_input = nn.Linear(256*4*4, 64 * 64)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(config.nc + 1, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, attr):\n",
        "        batch_size = x.size(0)\n",
        "        attr = attr.view(batch_size,256*4*4)\n",
        "        attr = self.feature_input(attr).view(-1, 1, 64, 64)\n",
        "        x = torch.cat([x, attr], 1)\n",
        "        return self.main(x).view(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vAlhZJSVDS",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17f6cv_DRCxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate fixed sampling vectors\n",
        "for n in range(10):\n",
        "    disp_z = torch.empty(64,config.nz, device=device)\n",
        "    disp_y = torch.empty(64,config.nfeature, device=device)\n",
        "for k in range(4):\n",
        "    aux_z = torch.randn(1,config.nz)\n",
        "    for i in range(16):\n",
        "        disp_z[i+16*k,:] = aux_z\n",
        "for k in range(4):\n",
        "    for j in range(8):\n",
        "        disp_y[j+16*k,:] = dataset[j+4][1]\n",
        "        disp_y[j+16*k+8,:] = dataset[j+4][1]*torch.from_numpy(np.random.binomial(1,0.7,(1,config.nfeature)))\n",
        "\n",
        "import torch.optim as optim\n",
        "loss = nn.MSELoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5gGTJ2kRC1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "4f2e0248-f845-4840-a0b8-aa50d8b9ff44"
      },
      "source": [
        "# CHOOSE NET\n",
        "if config.gan_type == 'scgan':    \n",
        "    netD = Discriminator_scgan().to(device)\n",
        "    config.no_miss_p = 1\n",
        "elif config.gan_type == 'pcgan':  \n",
        "    netD = Discriminator_pcgan().to(device)\n",
        "    config.no_miss_p = 0.85\n",
        "netG = Generator().to(device)\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "optim_d = optim.Adam(netD.parameters(),lr = config.lr_d, betas = Betas)\n",
        "optim_g = optim.Adam(netG.parameters(),lr = config.lr_g, betas = Betas)\n",
        "\n",
        "for epoch in range(config.nepoch):\n",
        "    running_g_loss = torch.tensor([0.0],device = device)\n",
        "    running_d_loss = torch.tensor([0.0],device = device)\n",
        "    epoch_d_acc = torch.tensor([0.0],device = device)\n",
        "\n",
        "    for i, (data, attr) in enumerate(dataloader, 0):\n",
        "        \n",
        "        batch_size = data.size(0)\n",
        "\n",
        "        # Train DISCRIMINATOR\n",
        "        netD.zero_grad()\n",
        "\n",
        "        noise = Variable(torch.FloatTensor(batch_size, config.nz, 1, 1).to(device))\n",
        "        label_real = Variable(torch.FloatTensor(batch_size, 1).fill_(1).to(device))\n",
        "        label_fake = Variable(torch.FloatTensor(batch_size, 1).fill_(0).to(device))\n",
        "\n",
        "        label_real.data.resize(batch_size, 1).fill_(1)\n",
        "        label_fake.data.resize(batch_size, 1).fill_(0)\n",
        "        noise.data.resize_(batch_size, config.nz, 1, 1).normal_(0, 1)\n",
        "        \n",
        "        attr = Variable(attr.to(device))\n",
        "        real = Variable(data.to(device))\n",
        "        \n",
        "        fake = netG(noise, attr)\n",
        "\n",
        "        if config.gan_type == 'pcgan':\n",
        "            turnoff = np.random.binomial(1,config.no_miss_p,(batch_size,config.nfeature))\n",
        "            turnoff = torch.from_numpy(turnoff).to(device)\n",
        "            attr = attr*turnoff\n",
        "            with torch.no_grad():\n",
        "                attr = netG.netF(attr)\n",
        "\n",
        "        d_real = netD(real, attr)         \n",
        "        d_fake = netD(fake.detach(), attr) # not update generator\n",
        "        \n",
        "        d_loss = loss(d_real, label_real) + loss(d_fake, label_fake) # real label\n",
        "        d_loss.backward()\n",
        "        optim_d.step()\n",
        "        running_d_loss += d_loss\n",
        "\n",
        "        # train GENERATOR\n",
        "        netG.zero_grad()\n",
        "        d_fake = netD(fake, attr)\n",
        "        g_loss = loss(d_fake, label_real) # trick the fake into being real\n",
        "        g_loss.backward()\n",
        "        optim_g.step()\n",
        "        running_g_loss += g_loss\n",
        "        \n",
        "    print('[%d/%d] Loss_D: %.2f Loss_G: %.2f' % (epoch, config.nepoch, running_d_loss.item(), running_g_loss.item()))\n",
        "    print('saving the output')\n",
        "    # torch.save(netG.state_dict(), config.result_dir+'/'+config.gan_type+'netG.pth')\n",
        "    # torch.save(netD.state_dict(), config.result_dir+'/'+config.gan_type+'netD.pth')\n",
        "    with torch.no_grad():\n",
        "        fake = netG(disp_z,disp_y)\n",
        "        vutils.save_image(fake.detach(),config.result_dir+'/'+config.gan_type+'samples_e_%03d.png' % (epoch),normalize=True,nrow = 8)\n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/15] Loss_D: 2371.24 Loss_G: 5473.91\n",
            "saving the output\n",
            "[1/15] Loss_D: 1200.01 Loss_G: 2553.60\n",
            "saving the output\n",
            "[2/15] Loss_D: 999.71 Loss_G: 2481.35\n",
            "saving the output\n",
            "[3/15] Loss_D: 970.67 Loss_G: 2490.55\n",
            "saving the output\n",
            "[4/15] Loss_D: 887.10 Loss_G: 2559.71\n",
            "saving the output\n",
            "[5/15] Loss_D: 813.21 Loss_G: 2653.67\n",
            "saving the output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cf303f66dfe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlabel_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabel_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}